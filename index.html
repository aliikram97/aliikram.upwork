<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ali Ikram - AI Specialist & Tech Lead</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #0066ff;
            --secondary: #00d9ff;
            --dark: #0a0e27;
            --darker: #050813;
            --light: #ffffff;
            --gray: #8892b0;
            --accent: #64ffda;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: var(--darker);
            color: var(--gray);
            line-height: 1.6;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Navigation */
        nav {
            position: fixed;
            top: 0;
            width: 100%;
            background: rgba(10, 14, 39, 0.95);
            backdrop-filter: blur(10px);
            z-index: 1000;
            padding: 20px 0;
            border-bottom: 1px solid rgba(100, 255, 218, 0.1);
        }

        nav .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            font-size: 24px;
            font-weight: bold;
            color: var(--accent);
        }

        nav ul {
            display: flex;
            list-style: none;
            gap: 30px;
        }

        nav a {
            color: var(--gray);
            text-decoration: none;
            transition: color 0.3s;
        }

        nav a:hover {
            color: var(--accent);
        }

        /* Hero Section */
        .hero {
            min-height: 100vh;
            display: flex;
            align-items: center;
            padding-top: 80px;
            position: relative;
        }

        .hero-content {
            max-width: 800px;
        }

        .hero-subtitle {
            color: var(--accent);
            font-size: 18px;
            margin-bottom: 20px;
        }

        .hero h1 {
            font-size: 64px;
            color: var(--light);
            margin-bottom: 20px;
            line-height: 1.1;
        }

        .hero h2 {
            font-size: 48px;
            color: var(--gray);
            margin-bottom: 30px;
        }

        .hero p {
            font-size: 18px;
            max-width: 600px;
            margin-bottom: 40px;
        }

        /* Video Placeholder */
        .video-placeholder {
            position: relative;
            width: 100%;
            padding-bottom: 56.25%;
            background: linear-gradient(135deg, rgba(0, 102, 255, 0.1), rgba(100, 255, 218, 0.1));
            border-radius: 12px;
            overflow: hidden;
            border: 2px solid rgba(100, 255, 218, 0.2);
            cursor: pointer;
            transition: transform 0.3s, border-color 0.3s;
        }

        .video-placeholder:hover {
            transform: scale(1.02);
            border-color: var(--accent);
        }

        .video-placeholder-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
        }

        .play-icon {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: rgba(100, 255, 218, 0.2);
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 20px;
            border: 2px solid var(--accent);
        }

        .play-icon::after {
            content: '';
            width: 0;
            height: 0;
            border-left: 20px solid var(--accent);
            border-top: 12px solid transparent;
            border-bottom: 12px solid transparent;
            margin-left: 5px;
        }

        .video-label {
            color: var(--accent);
            font-size: 16px;
        }

        /* Buttons */
        .btn {
            display: inline-block;
            padding: 15px 35px;
            background: transparent;
            color: var(--accent);
            border: 2px solid var(--accent);
            border-radius: 5px;
            text-decoration: none;
            transition: all 0.3s;
            margin-right: 15px;
        }

        .btn:hover {
            background: rgba(100, 255, 218, 0.1);
            transform: translateY(-2px);
        }

        /* Section Styles */
        section {
            padding: 100px 0;
        }

        .section-title {
            font-size: 42px;
            color: var(--light);
            margin-bottom: 50px;
            position: relative;
            display: inline-block;
        }

        .section-title::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, var(--accent), transparent);
        }

        /* Experience */
        .experience-item {
            margin-bottom: 50px;
            padding: 30px;
            background: rgba(100, 255, 218, 0.03);
            border-left: 3px solid var(--accent);
            border-radius: 5px;
            transition: transform 0.3s, background 0.3s;
        }

        .experience-item:hover {
            transform: translateX(10px);
            background: rgba(100, 255, 218, 0.05);
        }

        .experience-header {
            display: flex;
            justify-content: space-between;
            align-items: start;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }

        .experience-title {
            color: var(--light);
            font-size: 24px;
            margin-bottom: 5px;
        }

        .experience-company {
            color: var(--accent);
            font-size: 18px;
        }

        .experience-date {
            color: var(--gray);
            font-size: 14px;
        }

        .experience-item ul {
            list-style: none;
            padding-left: 0;
        }

        .experience-item li {
            padding-left: 25px;
            position: relative;
            margin-bottom: 10px;
        }

        .experience-item li::before {
            content: '‚ñπ';
            position: absolute;
            left: 0;
            color: var(--accent);
        }

        /* Projects Grid */
        .projects-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 30px;
            margin-top: 50px;
        }

        .project-card {
            background: rgba(100, 255, 218, 0.03);
            padding: 30px;
            border-radius: 10px;
            border: 1px solid rgba(100, 255, 218, 0.1);
            transition: transform 0.3s, border-color 0.3s;
            display: flex;
            flex-direction: column;
            height: 100%;
        }

        .project-card:hover {
            transform: translateY(-5px);
            border-color: var(--accent);
        }

        .project-card h3 {
            color: var(--light);
            font-size: 20px;
            margin-bottom: 15px;
            min-height: 60px;
        }

        .intro-video-section {
    padding: 100px 0;
}

.video-wrapper {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
    border-radius: 12px;
    border: 2px solid rgba(100, 255, 218, 0.2);
}

.video-wrapper iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border-radius: 10px;
}

        .project-card p {
            flex-grow: 1;
            margin-bottom: 20px;
        }

        .project-video {
            margin: 20px 0;
            aspect-ratio: 16/9;
        }

        .project-video video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .project-links {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }

        .project-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 8px 16px;
            background: rgba(100, 255, 218, 0.1);
            color: var(--accent);
            text-decoration: none;
            border-radius: 5px;
            font-size: 14px;
            transition: all 0.3s;
            border: 1px solid rgba(100, 255, 218, 0.2);
        }

        .project-link:hover {
            background: rgba(100, 255, 218, 0.2);
            transform: translateY(-2px);
        }

        .github-icon {
            width: 16px;
            height: 16px;
        }

        /* Skills */
        .skills-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 30px;
        }

        .skill-category {
            background: rgba(100, 255, 218, 0.03);
            padding: 25px;
            border-radius: 10px;
            border: 1px solid rgba(100, 255, 218, 0.1);
        }

        .skill-category h3 {
            color: var(--accent);
            margin-bottom: 15px;
            font-size: 18px;
        }

        .skill-category ul {
            list-style: none;
        }

        .skill-category li {
            padding: 5px 0;
            color: var(--gray);
        }

        /* Contact
        .contact-content {
            max-width: 600px;
            margin: 0 auto;
            text-align: center;
        } */

        /* .contact-content h2 {
            color: var(--light);
            font-size: 36px;
            margin-bottom: 20px;
        }

        .contact-content p {
            margin-bottom: 40px;
        }

        .contact-links {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        } */

        /* Footer */
        footer {
            text-align: center;
            padding: 30px 0;
            border-top: 1px solid rgba(100, 255, 218, 0.1);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 42px;
            }

            .hero h2 {
                font-size: 32px;
            }

            nav ul {
                display: none;
            }

            .experience-header {
                flex-direction: column;
            }
        }

        /* Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .fade-in {
            animation: fadeInUp 0.8s ease-out;
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="container">
            <div class="logo">Ali Ikram</div>
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#projects">Projects</a></li>
                <li><a href="#skills">Skills</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Introduction Video Section -->
   <section class="intro-video-section">
    <div class="container">
        <h2 class="section-title">Introduction</h2>
        <div class="video-wrapper">
            <iframe 
                src="https://www.youtube.com/embed/31tNnBq8-Y8" 
                title="Introduction Video" 
                frameborder="0" 
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                allowfullscreen>
            </iframe>
        </div>
    </div>
</section>

    <!-- About Section -->
    <section id="about">
        <div class="container">
            <h2 class="section-title">About Me</h2>
            <p style="max-width: 800px; font-size: 18px; margin-bottom: 30px;">
                AI Specialist with 4+ years of experience designing, deploying, and scaling AI-driven automation, computer vision, and large language model (LLM) solutions. Proven expertise in leading cross-functional teams, optimizing algorithms for real-time systems, and deploying production-ready AI pipelines across cloud and edge platforms.
            </p>
            <p style="max-width: 800px; font-size: 18px;">
                I've delivered high-impact projects in autonomous driving, OCR, multilingual NLP, and anomaly detection. I'm adept at bridging research and business value by consulting startups and enterprises to integrate cutting-edge AI into their workflows.
            </p>
        </div>
    </section>

    <!-- Experience Section -->
    <section id="experience">
        <div class="container">
            <h2 class="section-title">Experience</h2>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Sr. AI Engineer</div>
                        <div class="experience-company">Intelligent Learning Machines (ILM)</div>
                    </div>
                    <div class="experience-date">2024 ‚Äì Present</div>
                </div>
                <ul>
                    <li>Spearheaded simulator-based validation for autonomous driving algorithms, potentially reducing scenario testing costs by 30%</li>
                    <li>Built digital twins for anomaly detection, achieving 75% detection precision in abnormal driving behaviors</li>
                    <li>Developed a safe city algorithm that generates alerts based on gun-based events</li>
                    <li>Developed a multilingual document parsing pipeline using PyTorch + TensorRT, enabling 3√ó faster edge deployment</li>
                    <li>Integrated LLM-based contextual understanding for enterprise documents</li>
                    <li>Deployed real-time AI on edge (NVIDIA Jetson) with inference latency under 100ms for safety-critical systems</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">AI Algorithm Tech Lead</div>
                        <div class="experience-company">99Technologies</div>
                    </div>
                    <div class="experience-date">2023 ‚Äì 2024</div>
                </div>
                <ul>
                    <li>Led a 3-member AI team delivering OCR pipelines with 95% accuracy, reducing manual BIOS configuration by 85% across clients</li>
                    <li>Mentored junior engineers in AI lifecycle management, boosting team productivity and code quality</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Consultant AI Engineer</div>
                        <div class="experience-company">ILM (Part-Time)</div>
                    </div>
                    <div class="experience-date">2023 ‚Äì 2024</div>
                </div>
                <ul>
                    <li>Advised on video localization & simulation algorithms for scenario-based testing in autonomous driving</li>
                    <li>Provided AI consulting for startups, helping design MVPs in traffic analytics, OCR, and chatbot systems</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Machine Learning Engineer</div>
                        <div class="experience-company">ILM</div>
                    </div>
                    <div class="experience-date">2022 ‚Äì 2023</div>
                </div>
                <ul>
                    <li>Designed lane detection and centering algorithms, ensuring robustness in adverse conditions, aligned with ISO 21448 safety requirements</li>
                    <li>Implemented mitigation algorithms for failure case detection, improving system resilience by 20%</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Computer Vision Engineer</div>
                        <div class="experience-company">TeReSol</div>
                    </div>
                    <div class="experience-date">2021 ‚Äì 2022</div>
                </div>
                <ul>
                    <li>Developed thermal tracking system up to 3km, deployed on NVIDIA TK1-based embedded hardware</li>
                    <li>Optimized vision pipeline to achieve real-time detection at 15 FPS on limited compute resources</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Projects Section -->
    <section id="projects">
        <div class="container">
            <h2 class="section-title">Featured Projects</h2>
            
            <div class="projects-grid">
                <div class="project-card">
                    <h3>Integrating Robot Physical Dimensions into Path Planning</h3>
                    </p>Hybrid Robot-Aware Path Planning System introduces an innovative approach that integrates robot dimensions 
                        directly into the navigation process using an initial binary map. Traditional path-planning algorithms 
                        often treat the robot as a unit point within the Cartesian coordinate system, ignoring its physical size 
                        and shape, which can lead to collisions or inefficient routing. Our proposed method modifies the available
                         trajectories by expanding obstacle boundaries in the binary map according to the robot‚Äôs actual dimensions. 
                         This enables any standard path-planning algorithm to inherently account for robot size without requiring 
                         changes to the algorithm itself or the addition of external sensors, ensuring safer and more realistic navigation.</p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/Vkb06CYRB6s" 
                            title="RAG LLM Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                    <div class="project-links">
                        <a href="https://github.com/aliikram97/Integrating-Robot-Physical-Dimensions-into-Path-Planning" class="project-link" target="_blank">
                            <svg class="github-icon" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            GitHub
                        </a>
                    </div>
                </div>

                <div class="project-card">
                    <h3>TalToTextTranslate a translation and transcription pipeline</h3>
                    <p>Audio Transcription and Translation Pipeline is an intelligent system designed to efficiently process long audio 
                        recordings by converting speech into text and translating it into multiple languages. The pipeline utilizes
                        Google‚Äôs Speech Recognition service, providing support for all languages recognized by Google, ensuring broad 
                        accessibility and accuracy across diverse accents and dialects. Once the audio is transcribed, the text is
                         seamlessly translated using the Googletrans library into any desired target language. This end-to-end solution 
                         is ideal for multilingual communication, content localization, and accessibility applications, enabling users 
                         to easily convert lengthy audio materials into readable, translated text while maintaining clarity, speed, and 
                         reliability.
                    </p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/o3ocww3zxcc" 
                            title="RAG LLM Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                    <div class="project-links">
                        <a href="https://github.com/aliikram97/Talk2TextTranslate" class="project-link" target="_blank">
                            <svg class="github-icon" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            GitHub
                        </a>
                    </div>
                </div>

                <div class="project-card">
                    <h3>Multilingual OCR System</h3>
                    <p>Multilingual OCR and Translation Pipeline is an advanced AI-driven system developed to extract, translate, 
                        and summarize text from images locally without relying on cloud processing. The pipeline enables users to 
                        upload or capture an image containing text in multiple languages, automatically detecting and extracting 
                        the content with high precision using Optical Character Recognition (OCR). Once extracted, the text is 
                        seamlessly translated into the user‚Äôs preferred language, followed by the generation of an executive summary 
                        that highlights the key insights and context. This end-to-end local solution ensures data privacy, 
                        fast performance, and reliable multilingual support for both professional and personal document processing.
                    </p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/1wZiVdbtG30" 
                            title="RAG LLM Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                    <div class="project-links">
                        <a href="https://github.com/aliikram97/multilingual-ocr-pipeline" class="project-link" target="_blank">
                            <svg class="github-icon" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            GitHub
                        </a>
                    </div>
                </div>

                <div class="project-card">
                    <h3>Thermal Object Tracking</h3>
                    <p>Infrared Object Tracking System is a high-performance, AI-powered solution designed for long-range thermal 
                        detection up to 3 kilometers. It is optimized for real-time object recognition and motion tracking on embedded 
                        hardware such as NVIDIA Jetson devices. The system employs a custom-designed algorithm that uses proprietary 
                        mathematical equations for occlusion detection, allowing it to maintain continuous tracking even when the target 
                        is partially hidden or passing through dense thermal clutter. This advanced approach ensures exceptional robustness, 
                        accuracy, and speed, making it suitable for surveillance, defense, and industrial monitoring applications where 
                        reliability and low-latency detection are mission-critical.</p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/v5YV0uikqlg" 
                            title="RAG LLM Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                    <div class="project-links">
                        <a href="https://github.com/aliikram97/tracking_pipeline" class="project-link" target="_blank">
                            <svg class="github-icon" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            GitHub
                        </a>
                    </div>
                </div>

                <div class="project-card">
                    <h3>Voice Sales Agent</h3>
                    <p>The Voice Sales Agent is an intelligent, AI-powered system designed to handle inbound calls, engage with 
                        customers naturally, and manage the entire sales inquiry process. It listens to callers, understands their 
                        needs using speech recognition and natural language understanding, and provides relevant responses or solutions 
                        in real time.

Beyond answering queries, the agent can schedule appointments or meetings by integrating seamlessly with the company‚Äôs calendar system, ensuring that leads and clients are automatically booked for follow-ups without human intervention. This automation streamlines customer interaction, reduces response times, and boosts overall efficiency in sales operations.</p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/WbV4NwhpMWI" 
                            title="RAG LLM Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                    <!-- <div class="project-links">
                        <a href="https://github.com/yourusername/safe-city" class="project-link" target="_blank">
                            <svg class="github-icon" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            GitHub
                        </a>
                    </div> -->
                </div>

                <div class="project-card">
                    <h3>Adaptive Cruise Control</h3>
                    <p>Traffic Sign Recognition and Adaptive Cruise Control System is an intelligent driver-assistance framework designed to enhance autonomous vehicle safety and decision-making. The system employs computer vision techniques and deep learning models to detect, classify, and interpret traffic signs in real time under varying weather and lighting conditions. Detected signs are then used to dynamically adjust the vehicle's speed and behavior through an adaptive cruise control module, ensuring compliance with road regulations and maintaining safe distances from surrounding vehicles. This integrated approach improves situational awareness, reduces human error, and contributes to the development of fully autonomous driving technologies with enhanced responsiveness and reliability on modern roads.</p>
                    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
                        <iframe 
                            src="https://www.youtube.com/embed/lqgHjVG0qaw" 
                            title="Adaptive Cruise Control Demo"
                            frameborder="0"
                            allowfullscreen
                            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                        </iframe>
                    </div>
                </div>

                <div class="project-card">
                <div class="project-card">
    <h3>RAG-Based Question Answering Bot (Local LLM)</h3>
    <p>
        This project showcases a fully local Retrieval-Augmented Generation (RAG) based Question Answering system built using HuggingFace, LangChain, Gradio, and ChromaDB.
        The bot runs entirely offline with a locally hosted LLM, ensuring data privacy and fast responses without relying on external APIs.
        Documents are embedded and stored in a ChromaDB vector database, enabling efficient semantic search and context retrieval.
        The retrieved information is then passed to the LLM via LangChain, allowing the model to generate highly accurate, context-grounded answers.
        A Gradio interface provides an intuitive frontend where users can upload documents, ask questions, and interact with the assistant in real time.
    </p>

    <div class="project-video" style="position: relative; width: 100%; padding-bottom: 56.25%; border-radius: 8px; overflow: hidden;">
        <iframe 
            src="https://www.youtube.com/embed/WgtyV0VlCTA" 
            title="RAG LLM Demo"
            frameborder="0"
            allowfullscreen
            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
        </iframe>
    </div>
</div>

            </div>
        </div>
    </section>

    <!-- Skills Section -->
    <section id="skills">
        <div class="container">
            <h2 class="section-title">Technical Skills</h2>
            
            <div class="skills-container">
                <div class="skill-category">
                    <h3>AI & Machine Learning</h3>
                    <ul>
                        <li>Deep Learning (CNNs, GANs, RL)</li>
                        <li>Large Language Models (LLMs)</li>
                        <li>RAG Systems</li>
                        <li>OCR & Document Processing</li>
                        <li>SLAM & Autonomous Systems</li>
                        <li>Object Detection & Segmentation</li>
                        <li>Stereo Vision & Depth Estimation</li>
                        <li>Tracking & Camera Calibration</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Frameworks & Libraries</h3>
                    <ul>
                        <li>PyTorch</li>
                        <li>TensorFlow</li>
                        <li>OpenCV</li>
                        <li>Hugging Face</li>
                        <li>Flask & Flask-SocketIO</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Edge Deployment</h3>
                    <ul>
                        <li>TensorRT</li>
                        <li>ONNX</li>
                        <li>OpenVINO</li>
                        <li>NVIDIA Jetson</li>
                        <li>Docker</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Cloud & DevOps</h3>
                    <ul>
                        <li>AWS (EC2, S3, SageMaker)</li>
                        <li>AWS Lambda & Bedrock</li>
                        <li>Azure</li>
                        <li>Git</li>
                        <li>n8n Automation</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Simulation & Robotics</h3>
                    <ul>
                        <li>ROS (Robot Operating System)</li>
                        <li>CARLA Simulator</li>
                        <li>Unreal Engine</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Programming Languages</h3>
                    <ul>
                        <li>Python</li>
                        <li>C++</li>
                        <li>MATLAB</li>
                        <li>Verilog</li>
                        <li>TypeScript</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section
    <section id="contact">
        <div class="container">
            <div class="contact-content">
                <h2 class="section-title" style="display: block; text-align: center;">Get In Touch</h2>
                <p>I'm currently open to new opportunities and collaborations. Whether you have a question or just want to say hi, feel free to reach out!</p>
                
                <div class="contact-links">
                    <a href="mailto:aliikram97@gmail.com" class="btn">Email Me</a>
                    <a href="https://linkedin.com/in/ali-i-5306b597" class="btn" target="_blank">LinkedIn</a>
                </div>

                <div style="margin-top: 40px;">
                    <p style="color: var(--gray); margin-bottom: 10px;">üìç Islamabad, Pakistan</p>
                    <p style="color: var(--gray);">üìû +92-335-5093011 | +92-303-0595669</p>
                </div>
            </div>
        </div> -->
    <!-- </section> -->

    <!-- Footer -->
    <footer>
        <div class="container">
            <p>¬© 2025 Ali Ikram. Built with passion for AI and innovation.</p>
        </div>
    </footer>

    <script>
        // Smooth scrolling
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }
            });
        });

        // Fade in animation on scroll
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -100px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        document.querySelectorAll('.experience-item, .project-card, .skill-category').forEach(el => {
            el.style.opacity = '0';
            el.style.transform = 'translateY(30px)';
            el.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(el);
        });
    </script>
</body>
</html>